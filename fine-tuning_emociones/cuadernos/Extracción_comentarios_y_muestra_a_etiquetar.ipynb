{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ob70rypV_Ne"
      },
      "outputs": [],
      "source": [
        "# ✅ Instala solo lo necesario\n",
        "!pip install --quiet langdetect tqdm\n",
        "\n",
        "# 📚 Librerías\n",
        "import pandas as pd\n",
        "import requests\n",
        "import random\n",
        "import time\n",
        "from langdetect import detect\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "# 📦 Archivos por categoría\n",
        "archivos = {\n",
        "    \"Palestina\": \"narrativas_palestina_clusterizadas.csv\",\n",
        "    \"Israel\": \"narrativas_israel_clusterizadas.csv\",\n",
        "    \"Internacional\": \"narrativas_internacional_clusterizadas.csv\",\n",
        "    \"Internacional Medio Oriente\": \"narrativas_internacional_medio_oriente_clusterizadas.csv\"\n",
        "}\n",
        "\n",
        "# 📊 Cargar resumen\n",
        "df_resumen = pd.read_csv(\"resumen_topicos_por_categoria.csv\")\n",
        "\n",
        "# 📓 Cargar log incremental (comentarios ya guardados)\n",
        "try:\n",
        "    log = pd.read_csv(\"log_comentarios_extraidos.csv\")\n",
        "    print(\"✅ Log cargado con\", len(log), \"comentarios.\")\n",
        "except FileNotFoundError:\n",
        "    log = pd.DataFrame(columns=[\"comment_id\", \"video_id\", \"categoria\", \"topic\", \"fecha\", \"text\"])\n",
        "    print(\"📁 Log creado desde cero.\")\n",
        "# 🔐 Lista de claves\n",
        "API_KEYS = [\n",
        "]\n",
        "def extraer_comentarios(video_id, categoria, topic, max_results=40):\n",
        "    global API_KEYS, log\n",
        "    comentarios = []\n",
        "\n",
        "    for api_key in API_KEYS:\n",
        "        url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={video_id}&maxResults={max_results}&textFormat=plainText&key={api_key}\"\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            data = response.json()\n",
        "            if 'items' not in data:\n",
        "                continue\n",
        "            for item in data['items']:\n",
        "                comment = item['snippet']['topLevelComment']['snippet']\n",
        "                comment_id = item['id']\n",
        "                text = comment['textDisplay']\n",
        "                fecha = comment['publishedAt'][:10]\n",
        "\n",
        "                # 🔁 evitar repetidos\n",
        "                if comment_id in log[\"comment_id\"].values:\n",
        "                    continue\n",
        "\n",
        "                # 🚫 evitar spam\n",
        "                if len(text) < 20 or any(x in text.lower() for x in ['http', '@', '#', 'subscribe']):\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    if detect(text) != \"en\":\n",
        "                        continue\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "                comentarios.append({\n",
        "                    \"comment_id\": comment_id,\n",
        "                    \"video_id\": video_id,\n",
        "                    \"categoria\": categoria,\n",
        "                    \"topic\": topic,\n",
        "                    \"fecha\": fecha,\n",
        "                    \"text\": text\n",
        "                })\n",
        "\n",
        "            break  # si funcionó con esta key, no sigue probando más\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    return comentarios\n",
        "# 📥 Cargar el log anterior (si existe)\n",
        "try:\n",
        "    log = pd.read_csv(\"log_comentarios_extraidos.csv\")\n",
        "    print(\"✅ Log cargado con\", len(log), \"comentarios anteriores.\")\n",
        "except FileNotFoundError:\n",
        "    log = pd.DataFrame(columns=[\"comment_id\", \"video_id\", \"categoria\", \"topic\", \"fecha\", \"text\"])\n",
        "    print(\"📁 Log creado desde cero.\")\n",
        "\n",
        "# 🔁 Parámetros ajustables\n",
        "N_VIDEOS_POR_TOPICO = 50\n",
        "MAX_COMENTARIOS_POR_VIDEO = 80\n",
        "\n",
        "todos_comentarios = []\n",
        "\n",
        "for _, row in df_resumen.iterrows():\n",
        "    categoria = row[\"Categoría\"]\n",
        "    archivo = archivos[categoria]\n",
        "    df_cat = pd.read_csv(archivo)\n",
        "\n",
        "    for t in range(8):  # Tópico 0 a 7\n",
        "        col = f\"Tópico_{t}\"\n",
        "        if pd.isna(row[col]):\n",
        "            continue\n",
        "\n",
        "        df_topico = df_cat[df_cat[\"topic\"] == t]\n",
        "        if len(df_topico) < N_VIDEOS_POR_TOPICO:\n",
        "            continue\n",
        "\n",
        "        videos_muestreados = df_topico.sample(N_VIDEOS_POR_TOPICO, random_state=random.randint(1, 10000))\n",
        "        for _, video in videos_muestreados.iterrows():\n",
        "            comentarios = extraer_comentarios(\n",
        "                video[\"video_id\"], categoria, t, max_results=MAX_COMENTARIOS_POR_VIDEO\n",
        "            )\n",
        "            todos_comentarios.extend(comentarios)\n",
        "\n",
        "# ✅ Combinar nuevos con antiguos (sin repetir)\n",
        "df_nuevos = pd.DataFrame(todos_comentarios)\n",
        "\n",
        "# Evitar duplicados antes de guardar\n",
        "df_total = pd.concat([log, df_nuevos], ignore_index=True)\n",
        "df_total = df_total.drop_duplicates(subset=[\"comment_id\"])\n",
        "\n",
        "# Guardar actualizado\n",
        "df_total.to_csv(\"log_comentarios_extraidos.csv\", index=False)\n",
        "\n",
        "print(f\"✅ Nuevos comentarios agregados: {len(df_nuevos)}\")\n",
        "print(f\"🧾 Total acumulado: {len(df_total)} comentarios únicos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8p--dohWZ6y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "ruta = \"/content/drive/MyDrive/comentarios_emociones\"\n",
        "os.makedirs(ruta, exist_ok=True)\n",
        "import shutil\n",
        "\n",
        "shutil.copy(\"/content/log_comentarios_extraidos.csv\", \"/content/drive/MyDrive/comentarios_emociones/log_comentarios_extraidos.csv\")\n",
        "archivos = [\n",
        "    \"log_comentarios_extraidos.csv\",\n",
        "    \"narrativas_internacional_clusterizadas.csv\",\n",
        "    \"narrativas_internacional_medio_oriente_clusterizadas.csv\",\n",
        "    \"narrativas_israel_clusterizadas.csv\",\n",
        "    \"narrativas_palestina_clusterizadas.csv\",\n",
        "    \"resumen_topicos_por_categoria.csv\"\n",
        "]\n",
        "\n",
        "for archivo in archivos:\n",
        "    origen = f\"/content/{archivo}\"\n",
        "    destino = f\"/content/drive/MyDrive/comentarios_emociones/{archivo}\"\n",
        "    shutil.copy(origen, destino)\n",
        "    print(f\"✅ Copiado: {archivo}\")\n",
        "import pandas as pd\n",
        "\n",
        "archivos_narrativas = {\n",
        "    \"Palestina\": \"narrativas_palestina_clusterizadas.csv\",\n",
        "    \"Israel\": \"narrativas_israel_clusterizadas.csv\",\n",
        "    \"Internacional\": \"narrativas_internacional_clusterizadas.csv\",\n",
        "    \"Internacional Medio Oriente\": \"narrativas_internacional_medio_oriente_clusterizadas.csv\"\n",
        "}\n",
        "\n",
        "conteo_videos = []\n",
        "\n",
        "for categoria, archivo in archivos_narrativas.items():\n",
        "    df_temp = pd.read_csv(archivo)\n",
        "    total_videos = df_temp[\"video_id\"].nunique()\n",
        "    conteo_videos.append({\"categoria\": categoria, \"total_videos\": total_videos})\n",
        "\n",
        "df_conteo = pd.DataFrame(conteo_videos)\n",
        "df_conteo\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar desde Colab\n",
        "df_comments_test = pd.read_csv(\"/content/log_comentarios_extraidos.csv\")\n",
        "\n",
        "# Crear muestra balanceada: 8000 comentarios proporcionales por categoría/tópico\n",
        "grupo = df_comments_test.groupby([\"categoria\", \"topic\"])\n",
        "proporciones = (grupo.size() / grupo.size().sum() * 8000).astype(int).reset_index(name=\"n_muestra\")\n",
        "\n",
        "df_sample = pd.DataFrame()\n",
        "for _, row in proporciones.iterrows():\n",
        "    muestra = df_comments_test[\n",
        "        (df_comments_test[\"categoria\"] == row[\"categoria\"]) &\n",
        "        (df_comments_test[\"topic\"] == row[\"topic\"])\n",
        "    ].sample(n=row[\"n_muestra\"], random_state=42)\n",
        "    df_sample = pd.concat([df_sample, muestra], ignore_index=True)\n",
        "\n",
        "# Columnas para etiquetado\n",
        "df_sample[\"emocion_sugerida\"] = \"\"\n",
        "df_sample[\"emocion_corregida\"] = \"\"\n",
        "\n",
        "# Guardar muestra en tu Drive\n",
        "df_sample.to_csv(\"/content/drive/MyDrive/comentarios_emociones/muestra_etiquetado_ollama.csv\", index=False)\n",
        "print(\"✅ Muestra de 8000 comentarios lista y guardada en tu Google Drive.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
